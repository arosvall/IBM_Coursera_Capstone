{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation, training and evaluation of a CNN using TensorFlow backend Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALl needed modules for the code\n",
    "from tensorflow.python.keras.models import load_model, save_model\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array, ImageDataGenerator\n",
    "from tensorflow.python.keras import backend as bkend\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import cv2\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model, Input\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Average\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in images\n",
    "The below code is taken and slightly adapted from the given code within test.py template in the project handout. It reads in images, transfers them to arrays and sets them up to be run through the CNN later in the code. First the seed is set, then the methods are set up before being called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds to ensure the reproducible results\n",
    "SEED = 309\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(test_data_dir, image_size, training):\n",
    "    \"\"\"\n",
    "    Load images from local directory\n",
    "    :return: the image list (encoded as an array)\n",
    "    \"\"\"\n",
    "    # loop over the input images\n",
    "    images_data = []\n",
    "    labels = []\n",
    "    imagePaths = sorted(list(paths.list_images(test_data_dir)))\n",
    "    for imagePath in imagePaths:\n",
    "        # load the image, pre-process it, and store it in the data list\n",
    "       \n",
    "        img = cv2.imread(imagePath)\n",
    "        img = cv2.resize(img, image_size)\n",
    "        image = img_to_array(img)\n",
    "        images_data.append(image)\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        labels.append(label)\n",
    "        # extract the class label from the image path and update the\n",
    "        # labels list\n",
    "    return images_data, sorted(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code which was used to create extra images from the given dataset, enriching the data and providing more variety to the dataset. It has been commented out as it was run once, adding the images created to a file where they were then moved into the correct training and test data files before being included when training and testing the CNN. It has been included to show how the images were generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #\n",
    " #   rand = random.uniform(0.0,1.0)\n",
    " #       #40% chance for an image to be changed or enhanced, options include blurring and rotations. Basic data preprocessing to artificially increase the data size\n",
    " #       if  rand < 0.2:\n",
    " #           if rand < 0.1:\n",
    " #               M = cv2.getRotationMatrix2D((100/2, 100/2), 90, 1)\n",
    " #               dst = cv2.warpAffine(img, M, image_size)\n",
    " #               images_data.append(dst)\n",
    " #               labels.append(label)\n",
    "            #Rotate 180 degrees\n",
    " #           rand = random.uniform(0.0,1.0)\n",
    " #           if rand < 0.1:\n",
    " #               M = cv2.getRotationMatrix2D((100/2, 100/2), 180, 1)\n",
    " #               dst = cv2.warpAffine(img, M, image_size)\n",
    " #               images_data.append(dst)\n",
    " #               labels.append(label)\n",
    "   \n",
    "            #Blur image\n",
    " #           rand = random.uniform(0.0,1.0)\n",
    " #           if rand < 0.1:\n",
    " #               blur = cv2.blur(img,(5,5))\n",
    " #               images_data.append(blur)\n",
    " #               labels.append(label)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_to_array(images, labels):\n",
    "    # Convert to numpy and do constant normalize\n",
    "    X_test = np.array(images, dtype = \"float\") / 255.0\n",
    "    y_test = np.array(labels)\n",
    "    \n",
    "\n",
    "    # Binarize the labels\n",
    "    lb = LabelBinarizer()\n",
    "    y_test = lb.fit_transform(y_test)\n",
    "\n",
    "    return X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code, taken from test.py was chosen over the imagedatagenerator option due to a rapid increase in speed due to the ability to run on the GPU of the computer the CNN was trained on. The imagedatagenerator code is included to show what could have been used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'train_data'\n",
    "test_data_dir = 'test_data'\n",
    "\n",
    "image_size = (100, 100)\n",
    "\n",
    "# Load images\n",
    "train_images, train_labels = load_images(train_data_dir, image_size, True)\n",
    "test_images, test_labels = load_images(test_data_dir, image_size, False)\n",
    "\n",
    "# Convert images to numpy arrays (images are normalized with constant 255.0), and binarize categorical labels\n",
    "training_data, training_labels = convert_img_to_array(train_images, train_labels)\n",
    "test_data, testing_labels = convert_img_to_array(test_images, test_labels)\n",
    "\n",
    "training_data_original=training_data.copy()\n",
    "test_data_original = test_data.copy()\n",
    "training_data_labels = training_labels.copy()\n",
    "testing_data_labels = testing_labels.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "#                                  horizontal_flip = True,\n",
    "#                                  vertical_flip = True,\n",
    "#                                  zoom_range=0.2,\n",
    "#                                  rotation_range = 90)\n",
    "\n",
    "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#traind = train_datagen.flow(training_data, training_labels, batch_size=32)\n",
    "#testd = test_datagen.flow(test_data, test_labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "Below is the model created from optimal combinations of loss functions, regularisation, number of layers etc as detailed in the report. This was the model which was saved to be used in test.py, and was one of the two used in the creation of an ensemble model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropout layer to remove risk of overfitting, removing half of the nodes\n",
    "#Final convolution and pooling layers, reducing size again with 2x2 filter size and pooling sizes\n",
    "#Flatten the data for dense input and to ensure later output is correct\n",
    "#Fully connected layer, followed by a 30% dropout layer\n",
    "#Final dense layer, outputs the classification of the image\n",
    "#Best settings found for the SGD optimiser\n",
    "#Model compiled with different optimiser and loss to model one, using second best settings to produce a more varied ensemble model\n",
    "\n",
    "\n",
    "\n",
    "classifier = Sequential()\n",
    "# First convolution and pooling layers, adding padding around the image at this stage to keep as much data integrity as possible before using a pooling layer with 4x4 size to reduce input to next convolution layer\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (100, 100, 3), padding = 'valid', activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (4, 4)))\n",
    "# Second convolution and pooling layer, reducing size again and applying 3x3 filters to the data\n",
    "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "#Dropout layer to remove risk of overfitting, removing half of the nodes\n",
    "classifier.add(Dropout(rate = 0.5))\n",
    "#Final convolution and pooling layers, reducing size again with 2x2 filter size and pooling sizes\n",
    "classifier.add(Conv2D(32, (2, 2), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#Flatten the data for dense input and to ensure later output is correct\n",
    "classifier.add(Flatten())\n",
    "#Fully connected layer, followed by a 30% dropout layer\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(rate = 0.2))\n",
    "#Final dense layer, outputs the classification of the image\n",
    "classifier.add(Dense(units = 3, activation = 'softmax'))\n",
    "#Best settings found for the Adam optimiser\n",
    "\n",
    "adam = optimizers.Adam(lr = 0.001) #Used due to the quick rate and ease of training, also good overall but not as good as sgd\n",
    "#Model compiled with different optimiser and loss to model two, using best settings to produce a more varied ensemble model\n",
    "classifier.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the CNN\n",
    "This is where the CNN is trained, with the data supplied in arrays created previously in the code. Time is included to see the amount of time taken to train the CNN. Epochs at 100 proved to be enough to train the CNN to a high accuracy, the validation split choice is discussed in the report and batches of 50 proved useful in getting a high accuracy but not exceeding technical limitations and causing memory out errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#start = time.time()\n",
    "classifier.fit(training_data, training_labels,\n",
    "batch_size = 50,\n",
    "validation_split = 0.1,\n",
    "verbose = 1,\n",
    "epochs = 100)\n",
    "#end = time.time()\n",
    "#print(end - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the CNN\n",
    "This is where the CNN is evaluated on the test data, which is entirely unseen data. The CNN is then saved to the models file to be used later in test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "scores = classifier.evaluate(training_data, training_labels)\n",
    "#print(\"\\n%s: %.2f%%\" % (classifier.metrics_names[1], scores[1]*100))\n",
    "print(\"Train loss:{} \\n Train accuracy:{}\".format(scores[0], scores[1]*100))\n",
    "\n",
    "scores = classifier.evaluate(test_data, testing_labels)\n",
    "#print(\"\\n%s: %.2f%%\" % (classifier.metrics_names[1], scores[1]*100))\n",
    "print(\"Test loss:{} \\n Test accuracy:{}\".format(scores[0], scores[1]*100))\n",
    "\n",
    "#classifier.save('models/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Late EDA\n",
    "In this portion of the code three random images are selected from the dataset and displayed, showing their prediction probabilities for each class in order to see how the CNN is performing on a few limited options to give an idea of noise in image impacting overall accuracy (often seen where too much green in a cherry picture causes an assumption that the image is a tomato)\n",
    "The images are displayed as blue due to how openCV reads them in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = np.random.randint(test_data.shape[0])\n",
    "rand_image = test_data_original[rand_index]\n",
    "plt.imshow(rand_image)\n",
    "\n",
    "print(\"Y prediction:{}\".format(classifier.predict(np.array([test_data[rand_index],]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = np.random.randint(test_data.shape[0])\n",
    "rand_image = test_data_original[rand_index]\n",
    "plt.imshow(rand_image)\n",
    "\n",
    "print(\"Y prediction:{}\".format(classifier.predict(np.array([test_data[rand_index],]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = np.random.randint(test_data.shape[0])\n",
    "rand_image = test_data_original[rand_index]\n",
    "plt.imshow(rand_image)\n",
    "\n",
    "print(\"Y prediction:{}\".format(classifier.predict(np.array([test_data[rand_index],]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second CNN Model\n",
    "Below is the code written to create a second CNN model, train it then run this model with the first model created to create an ensemble model. The ensemble model will make predictions on the test data but does not go any further. Given more time the data would ideally be compared to the actual labelled class to give a full comparison of accuracy and loss. This was included in the train.py notebook to show the attempt made and that some steps worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = Sequential()\n",
    "# First convolution and pooling layers, adding padding around the image at this stage to keep as much data integrity as possible before using a pooling layer with 4x4 size to reduce input to next convolution layer\n",
    "classifier2.add(Conv2D(32, (3, 3), input_shape = (100, 100, 3), padding = 'valid', activation = 'relu'))\n",
    "classifier2.add(MaxPooling2D(pool_size = (4, 4)))\n",
    "# Second convolution and pooling layer, reducing size again and applying 3x3 filters to the data\n",
    "classifier2.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "classifier2.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "#Dropout layer to remove risk of overfitting, removing half of the nodes\n",
    "classifier2.add(Dropout(rate = 0.5))\n",
    "#Final convolution and pooling layers, reducing size again with 2x2 filter size and pooling sizes\n",
    "classifier2.add(Conv2D(64, (2, 2), activation = 'relu'))\n",
    "classifier2.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "#Flatten the data for dense input and to ensure later output is correct\n",
    "classifier2.add(Flatten())\n",
    "#Fully connected layer, followed by a 30% dropout layer\n",
    "classifier2.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier2.add(Dropout(rate = 0.2))\n",
    "#Final dense layer, outputs the classification of the image\n",
    "classifier2.add(Dense(units = 3, activation = 'softmax'))\n",
    "#Best settings found for the SGD optimiser\n",
    "sgd = optimizers.SGD(lr=0.01, momentum=0.5)\n",
    "#Model compiled with different optimiser and loss to model one, using second best settings to produce a more varied ensemble model\n",
    "classifier2.compile(optimizer = sgd, loss = 'mse', metrics = ['categorical_accuracy'])\n",
    "classifier2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier with training data and labels created as arrays, using a batch size of 32 due to restricted tech and running for 100 epochs to give sgd best rate to train at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2.fit(training_data, training_labels,\n",
    "batch_size = 32,\n",
    "validation_split = 0.1,\n",
    "verbose = 1,\n",
    "epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation, same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "scores = classifier2.evaluate(training_data, training_labels)\n",
    "print(\"Train loss:{} \\n Train accuracy:{}\".format(scores[0], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (classifier.metrics_names[1], scores[1]*100))\n",
    "\n",
    "scores = classifier2.evaluate(test_data, testing_labels)\n",
    "print(\"Test loss:{} \\n Test accuracy:{}\".format(scores[0], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (classifier.metrics_names[1], scores[1]*100))\n",
    "\n",
    "classifier2.save('models/sgdmodel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model\n",
    "The below code is to create an ensemble model and was heavily inspired by from: https://medium.com/randomai/ensemble-and-store-models-in-keras-2-x-b881a6d7693f The ensemble model does not work yet, predicting correctly but not getting an overall accuracy/loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [classifier, classifier2]\n",
    "\n",
    "def ensembleModels(models, model_input):\n",
    "    # collect outputs of models in a list\n",
    "    yModels=[model(model_input) for model in models] \n",
    "    # averaging outputs\n",
    "    yAvg=layers.average(yModels) \n",
    "    # build model from same input and avg output\n",
    "    modelEns = Model(inputs=model_input, outputs=yAvg, name='ensemble')  \n",
    "   \n",
    "    return modelEns\n",
    "\n",
    "model_input = Input(shape=models[0].input_shape[1:])\n",
    "modelEns = ensembleModels(models, model_input)\n",
    "modelEns.summary()\n",
    "\n",
    "predictions = modelEns.predict(test_data)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
